{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Klasifikasi teks metode naive bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "import tkinter.font as font\n",
    "from tkinter import *\n",
    "from tkinter import ttk\n",
    "from time import strftime\n",
    "from tkinter import ttk, filedialog, messagebox\n",
    "import pandas as pd\n",
    "import string \n",
    "import re #regex library\n",
    "import nltk\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize \n",
    "from nltk.probability import FreqDist\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "import tkinter.scrolledtext as tkst\n",
    "#from time import strftime\n",
    "import swifter\n",
    "from tkinter import messagebox as msg\n",
    "from pandastable import Table\n",
    "from tkintertable import TableCanvas\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "import matplotlib\n",
    "#matplotlib.use(\"TkAgg\")\n",
    "from matplotlib.figure import Figure\n",
    "from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg\n",
    "from matplotlib.backend_bases import key_press_handler\n",
    "from typing import Callable\n",
    "\n",
    "root = Tk()\n",
    "s = ttk.Style()\n",
    "s.configure(\"lb.TLabel\", foreground=\"aliceblue\", background=\"aliceblue\")\n",
    "label_files = ttk.Label(root,text=\"No File Selected\", style=\"lb.TLabel\")\n",
    "label_files.place(rely=0, relx=0) \n",
    "\n",
    "def File_dialog():\n",
    "    \"\"\"This function will open the file explorer\"\"\"\n",
    "    global filename\n",
    "    filename = filedialog.askopenfilename(initialdir='C:/Tutorial',\n",
    "                                          title=\"Select A File\",\n",
    "                                          filetype=((\"xlsx files\", \"*.xlsx\"), (\"all files\", \"*.*\")))\n",
    "    \n",
    "    s.configure(\"sn.TLabel\", foreground=\"DeepSkyBlue\",background=\"aliceblue\")\n",
    "    file_frame = tk.LabelFrame(root, text=\"Selected File Preprocessing\" ,bd =0\n",
    "                          ,bg ='aliceblue', fg = 'DeepSkyBlue')\n",
    "    file_frame.place(height=45, width=800, y=100, x=5)\n",
    "    label_file = ttk.Label(file_frame, text=filename,style=\"sn.TLabel\")\n",
    "    label_file.place(y=0, x=0)\n",
    "    label_files.configure(text=filename)\n",
    "    menubar.entryconfig(\"Preprocessing\", state=\"normal\")\n",
    "    \"\"\"\n",
    "    buttonplus = Button(root, text = 'Preprocessing', bd = '0', command = prins,\n",
    "             bg = 'lightblue', fg = 'white')#, width=6, height=2)\n",
    "    buttonplus.place(x=5, y=150)\n",
    "    buttonshow = Button(root, text = 'Show Tabel', bd = '0', command = showtabel1,\n",
    "             bg = 'lightblue', fg = 'white')#, width=6, height=2)\n",
    "    buttonshow.place(x=135, y=150)\n",
    "    buttonplus['font']=myFont\n",
    "    buttonshow['font']=myFont\n",
    "    \"\"\"\n",
    "    if filename =='':\n",
    "        label_file.config(text=\"Tidak ada data\")\n",
    "    \n",
    "    myFont = font.Font(family='Calibri', size=12, weight='bold')\n",
    "    file_frame['font']=myFont\n",
    "    label_file['font']=myFont\n",
    "    \n",
    "def showtabel1():\n",
    "    excel_filename = r\"{}\".format(label_files['text'])\n",
    "    review = pd.read_excel(excel_filename)\n",
    "    newindow = Toplevel(root)\n",
    "    newindow.title(filename)\n",
    "    newindow.geometry('720x400')\n",
    "    newindow.configure(bg=\"aliceblue\")\n",
    "    newindow.state(\"normal\")\n",
    "    f2 = Frame(newindow, height=200, width=300) \n",
    "    f2.pack(fill=BOTH,expand=1)\n",
    "    table = Table(f2, dataframe=review,read_only=True)\n",
    "    table.show()\n",
    "    #excel_filename = r\"{}\".format(label_files['text'])\n",
    "    #review = pd.read_excel(excel_filename)\n",
    "\n",
    "def prins():\n",
    "    excel_filename = r\"{}\".format(label_files['text'])\n",
    "    global komen\n",
    "    komen = pd.read_excel(excel_filename)\n",
    "    global output\n",
    "    output = pd.read_excel(excel_filename)\n",
    "    global review\n",
    "    review = pd.read_excel(excel_filename)\n",
    "    if (len(review)== 0):\n",
    "        print ('No records', 'No records')\n",
    "    else:\n",
    "        pass\n",
    "    global labeld\n",
    "    labeld = komen['label']\n",
    "    global komentarasli\n",
    "    komentarasli = komen['komentar']\n",
    "    global komcasefold\n",
    "    komcasefold = output['komentar'].str.lower()\n",
    "    output['komentar']= output['komentar'].str.lower()\n",
    "    review['komentar'] = review['komentar'].str.lower()\n",
    "    \n",
    "    def remove_komentar_special(text):\n",
    "        # remove tab, new line, ans back slice\n",
    "        text = str(text).replace('\\\\t',\" \").replace('\\\\n',\" \").replace('\\\\u',\" \").replace('\\\\',\"\")\n",
    "        # remove non ASCII (emoticon, chinese word, .etc)\n",
    "        text = text.encode('ascii', 'replace').decode('ascii')\n",
    "        # remove mention, link, hashtag\n",
    "        text = ' '.join(re.sub(\"([@#][A-Za-z0-9]+)|(\\w+:\\/\\/\\S+)\",\" \", text).split())\n",
    "        # remove incomplete URL\n",
    "        return text.replace(\"http://\", \" \").replace(\"https://\", \" \")\n",
    "    review['komentar'] = review['komentar'].apply(remove_komentar_special)\n",
    "    global komclean\n",
    "    output['komentar']= output['komentar'].apply(remove_komentar_special)\n",
    "    def remove_number(text):\n",
    "        return  re.sub(r\"\\d+\", \"\", text)\n",
    "    \n",
    "    output['komentar']= output['komentar'].apply(remove_number)\n",
    "    review['komentar'] = review['komentar'].apply(remove_number)\n",
    "    \n",
    "    #remove punctuation\n",
    "    def remove_punctuation(text):\n",
    "        return text.translate(str.maketrans(\"\",\"\",string.punctuation))\n",
    "    \n",
    "    output['komentar']= output['komentar'].apply(remove_punctuation)\n",
    "    review['komentar'] = review['komentar'].apply(remove_punctuation)\n",
    "\n",
    "    #remove whitespace leading & trailing\n",
    "    def remove_whitespace_LT(text):\n",
    "        return text.strip()\n",
    "\n",
    "    output['komentar']= output['komentar'].apply(remove_whitespace_LT)\n",
    "    review['komentar'] = review['komentar'].apply(remove_whitespace_LT)\n",
    "\n",
    "    #remove multiple whitespace into single whitespace\n",
    "    def remove_whitespace_multiple(text):\n",
    "        return re.sub('\\s+',' ',text)\n",
    "    \n",
    "    output['komentar']= output['komentar'].apply(remove_whitespace_multiple)\n",
    "    review['komentar'] = review['komentar'].apply(remove_whitespace_multiple)\n",
    "\n",
    "    # remove single char\n",
    "    def remove_singl_char(text):\n",
    "        return re.sub(r\"\\b[a-zA-Z]\\b\", \"\", text)\n",
    "\n",
    "    review['komentar'] = review['komentar'].apply(remove_singl_char)\n",
    "    output['komentar']= output['komentar'].apply(remove_singl_char)\n",
    "    \n",
    "    # NLTK word Tokenize \n",
    "    def word_tokenize_wrapper(text):\n",
    "        return word_tokenize(text)\n",
    "\n",
    "    review['komentar_token'] = review['komentar'].apply(word_tokenize_wrapper)\n",
    "    #print('Hasil Cleaning-Tokenizing : \\n') \n",
    "    #print(review_data['komentar_token'].head(5))\n",
    "    #print('\\n\\n\\n')\n",
    "    \"\"\"\n",
    "    # ------- Normalisasi -------\n",
    "\n",
    "    normalizad_word = pd.read_excel(\"normalisasi.xlsx\")\n",
    "\n",
    "    normalizad_word_dict = {}\n",
    "\n",
    "    for index, row in normalizad_word.iterrows():\n",
    "        if row[0] not in normalizad_word_dict:\n",
    "            normalizad_word_dict[row[0]] = row[1] \n",
    "\n",
    "    def normalized_term(document):\n",
    "        return [normalizad_word_dict[term] if term in normalizad_word_dict else term for term in document]\n",
    "\n",
    "    review['komentar_normalisasi'] = review['komentar_token'].apply(normalized_term)\n",
    "    \"\"\"\n",
    "    \n",
    "    # ------- Stopword -------\n",
    "\n",
    "    list_stopwords = stopwords.words('indonesia')\n",
    "\n",
    "    # menambah additional stopword\n",
    "    list_stopwords.extend([\"yg\", \"dg\", \"rt\", \"dgn\", \"ny\", \"d\", 'klo', \n",
    "                       'kalo', 'amp', 'biar', 'bikin', 'bilang', \n",
    "                       'krn', 'nya', 'nih', 'sih', \n",
    "                       'si', 'tau', 'tuh', 'utk', \n",
    "                       'jd', 'jgn', 'sdh', 'aja', 'n', 't', \n",
    "                       'nyg', 'hehe', 'pen', 'u', 'nan', 'loh', 'rt',\n",
    "                       '&amp', 'yah','apa','pada','pakai','pengin','tepi'])\n",
    "\n",
    "    # convert list to dictionary\n",
    "    list_stopwords = set(list_stopwords)\n",
    "\n",
    "    #remove stopword pada list token\n",
    "    def stopwords_removal(words):\n",
    "        return [word for word in words if word not in list_stopwords]\n",
    "\n",
    "    review['komentar_token_stopwords'] = review['komentar_token'].apply(stopwords_removal) \n",
    "    \n",
    "    # ------- Normalisasi -------\n",
    "\n",
    "    normalizad_word = pd.read_excel(\"normalisasi.xlsx\")\n",
    "\n",
    "    normalizad_word_dict = {}\n",
    "\n",
    "    for index, row in normalizad_word.iterrows():\n",
    "        if row[0] not in normalizad_word_dict:\n",
    "            normalizad_word_dict[row[0]] = row[1] \n",
    "\n",
    "    def normalized_term(document):\n",
    "        return [normalizad_word_dict[term] if term in normalizad_word_dict else term for term in document]\n",
    "\n",
    "    review['komentar_normalisasi'] = review['komentar_token_stopwords'].apply(normalized_term)\n",
    "\n",
    "    #review_data['komentar_normalisasi'].head()\n",
    "    \n",
    "\n",
    "    # ------- Stemming -------\n",
    "\n",
    "    factory = StemmerFactory()\n",
    "    stemmer = factory.create_stemmer()\n",
    "\n",
    "    # stemmed\n",
    "    def stemmed_wrapper(term):\n",
    "        return stemmer.stem(term)\n",
    "\n",
    "    term_dict = {}\n",
    "\n",
    "    for document in review['komentar_normalisasi']:\n",
    "        for term in document:\n",
    "            if term not in term_dict:\n",
    "                term_dict[term] = ' '\n",
    "            \n",
    "    print(len(term_dict))\n",
    "    print(\"------------------------\")\n",
    "\n",
    "    for term in term_dict:\n",
    "        term_dict[term] = stemmed_wrapper(term)\n",
    "        print(term,\":\" ,term_dict[term])\n",
    "    \n",
    "    print(term_dict)\n",
    "    print(\"------------------------\")\n",
    "\n",
    "\n",
    "    # apply stemmed term to dataframe\n",
    "    def get_stemmed_term(document):\n",
    "        return [term_dict[term] for term in document]\n",
    "\n",
    "    review['komentar_stemmed'] = review['komentar_normalisasi'].swifter.apply(get_stemmed_term)\n",
    "    \n",
    "    df_rows = review.to_numpy().tolist()\n",
    "    print(\"gnissecorperp id lisahreb halet atad\")\n",
    "    #myFont = font.Font(family='Helvetica', size=12, weight='bold')\n",
    "    #labelprep=Label(root, text=\"preprocessing berhasil\", bg = \"aliceblue\").place(x=5, y=300)\n",
    "    #labelprep['font']=myFont\n",
    "    #labelpres=Frame(master = root, bg = 'aliceblue')\n",
    "    #buttonshow.place(x=120, y=150)\n",
    "    label_file = ttk.Label(root, text=\"Data berhasil diproses\",style=\"sn.TLabel\")\n",
    "    label_file.place(x=5, y=150)\n",
    "    \n",
    "    myFont = font.Font(family='calibri', size=12, weight='bold')\n",
    "    \"\"\"\n",
    "    buttonshow = Button(root, text = 'Show Tabel', bd = '0', command = showtabel2,\n",
    "             bg = 'lightblue', fg = 'white')#, width=6, height=2)\n",
    "    buttonshow.place(x=5, y=220)\n",
    "   \n",
    "    myFont = font.Font(family='Helvetica', size=12, weight='bold')\n",
    "    \"\"\"\n",
    "    #buttonshow['font']=myFont\n",
    "    label_file['font']=myFont\n",
    "    #edit.entryconfig(\"Apply\", state=\"normal\")\n",
    "    edit.entryconfig(\"Save Data\", state=\"normal\")\n",
    "    edit.entryconfig(\"Hasil Preprocessing\", state=\"normal\")\n",
    "\n",
    "def exportExcel ():\n",
    "    \n",
    "    export_file_path = filedialog.asksaveasfilename(defaultextension='.xlsx')\n",
    "    review.to_excel (export_file_path, index = False, header=True)\n",
    "    \n",
    "def showtabel2():\n",
    "    #print(review['komentar_stemmed'])\n",
    "\n",
    "    dfkom = pd.DataFrame({\n",
    "    'komentar': komentarasli,\n",
    "    'label': labeld,\n",
    "    'komentar_casefolding' : komcasefold,\n",
    "    'komentar_cleaning': output['komentar'], \n",
    "    'komentar_tokenize': review['komentar_token'],\n",
    "    'komentar_stopword': review['komentar_token_stopwords'],\n",
    "    'komentar_normalisasi': review['komentar_normalisasi'],\n",
    "    'komentar_stemmed': review['komentar_stemmed']\n",
    "    })\n",
    "    newindow2 = Toplevel(root)\n",
    "    newindow2.title(\"Hasil preprocessing\")\n",
    "    #root.title('PandasTable Example')\n",
    "    newindow2.geometry('720x400')\n",
    "    newindow2.configure(bg=\"aliceblue\")\n",
    "    newindow2.state(\"normal\")\n",
    "    \n",
    "    f2 = Frame(newindow2, height=200, width=300) \n",
    "    f2.pack(fill=BOTH,expand=1)\n",
    "    table = Table(f2, dataframe=dfkom,read_only=True)\n",
    "    table.show()\n",
    "\n",
    "    \n",
    "def helpp():\n",
    "    msg.showinfo('Info',\n",
    "                '-Jika ingin melakukan preprocessing harap menyiapkan file berformat xlsx atau excel\\n-Untuk file excel yang di import/open harus memiliki kolom komentar\\n-Setelah proses preprocessing data disave')\n",
    "\n",
    "#global styl\n",
    "styl = ttk.Style()\n",
    "styl.configure(\"ide.TLabel\", foreground=\"aliceblue\", background=\"aliceblue\")\n",
    "global datalatih\n",
    "datlatih = ttk.Label(root,text=\"No File Selected\", styl=\"ide.TLabel\")\n",
    "datlatih.place(y=0, x=0)\n",
    "def inputlatih():\n",
    "    global filenamed\n",
    "    filenamed = filedialog.askopenfilename(initialdir='C:/Tutorial',\n",
    "                                          title=\"Select A File\",\n",
    "                                          filetype=((\"xlsx files\", \"*.xlsx\"), (\"all files\", \"*.*\")))\n",
    "    styl.configure(\"ye.TLabel\", foreground=\"DeepSkyBlue\",background=\"aliceblue\")\n",
    "    datlatihg = tk.LabelFrame(root, text=\"Selected Data Latih\" ,bd =0,bg ='aliceblue', fg = 'DeepSkyBlue')\n",
    "    datlatihg.place(height=45, width=800, y=180, x=5)\n",
    "    global datlatlabel\n",
    "    datlatlabel = ttk.Label(datlatihg, text=filenamed,style=\"ye.TLabel\")\n",
    "    datlatlabel.place(y=0, x=0)\n",
    "    datlatih.configure(text=filenamed)\n",
    "    myFont = font.Font(family='Calibri', size=12, weight='bold')\n",
    "    datlatihg['font']=myFont\n",
    "    datlatlabel['font']=myFont\n",
    "    if filenamed==\"\":\n",
    "        datlatlabel.configure(text=\"Tidak ada data\")\n",
    "    #menubar.entryconfig(\"Klasifikasi Naive Bayes\", state=\"normal\")\n",
    "    #sub_nevbayes.entryconfig(0, label = filenamed)\n",
    "    \n",
    "def converd():\n",
    "    global conlat\n",
    "    conlat = pd.DataFrame({\n",
    "    'komentar': komentarasli,\n",
    "    'label': labeld,\n",
    "    'komentar_casefolding' : komcasefold,\n",
    "    'komentar_cleaning': output['komentar'], \n",
    "    'komentar_tokenize': review['komentar_token'],\n",
    "    'komentar_stopword': review['komentar_token_stopwords'],\n",
    "    'komentar_mormalisasi': review['komentar_normalisasi'],\n",
    "    'komentar_stemmed': review['komentar_stemmed']\n",
    "    })\n",
    "    styl.configure(\"ye.TLabel\", foreground=\"DeepSkyBlue\",background=\"aliceblue\")\n",
    "    datlatihg = tk.LabelFrame(root, text=\"Selected Data Latih\" ,bd =0,bg ='aliceblue', fg = 'DeepSkyBlue')\n",
    "    datlatihg.place(height=45, width=800, y=180, x=5)\n",
    "    datlatlabel = ttk.Label(datlatihg, text=\"Data Latih Hasil Preprocessing\",style=\"ye.TLabel\")\n",
    "    datlatlabel.place(y=0, x=0)\n",
    "    myFont = font.Font(family='Calibri', size=12, weight='bold')\n",
    "    datlatihg['font']=myFont\n",
    "    datlatlabel['font']=myFont\n",
    "    #menubar.entryconfig(\"Klasifikasi Naive Bayes\", state=\"normal\")\n",
    "    sub_nevbayes.entryconfig(1, label = \"Selected Data Latih\")\n",
    "\n",
    "def showcondat():\n",
    "    df = conlat\n",
    "    newindow = Toplevel(root)\n",
    "    #newindow.title(datlatlabel)\n",
    "    newindow.geometry('720x400')\n",
    "    newindow.configure(bg=\"aliceblue\")\n",
    "    newindow.state(\"normal\")\n",
    "    f2 = Frame(newindow, height=200, width=300) \n",
    "    f2.pack(fill=BOTH,expand=1)\n",
    "    table = Table(f2, dataframe=df,read_only=True)\n",
    "    table.show()\n",
    "\n",
    "def showdatlatih():\n",
    "    global filedatlatih\n",
    "    filedatlatih = r\"{}\".format(datlatih['text'])\n",
    "    review = pd.read_excel(filedatlatih)\n",
    "    #train_dokumen.drop([\"no\", \"nama\",\"komentar\", \"tanggal scraping (17-02-2021)\", \"komentar_token\",\"komentar_token_stopwords\", \"komentar_normalisasi\"], axis = 1, inplace = True) \n",
    "    #train_dokumen['label'] = train_dokumen['label'].map({'positif':1 , 'negatif':0})\n",
    "    df = review[['komentar','label','komentar_token','komentar_token_stopwords','komentar_normalisasi','komentar_stemmed']]\n",
    "    newindow = Toplevel(root)\n",
    "    newindow.title(filenamed)\n",
    "    newindow.geometry('720x400')\n",
    "    newindow.configure(bg=\"aliceblue\")\n",
    "    newindow.state(\"normal\")\n",
    "    f2 = Frame(newindow, height=200, width=300) \n",
    "    f2.pack(fill=BOTH,expand=1)\n",
    "    table = Table(f2, dataframe=df,read_only=True)\n",
    "    table.show()\n",
    "    \n",
    "\n",
    "datuji = ttk.Label(root,text=\"No File Selected\", styl=\"ide.TLabel\")\n",
    "datuji.place(y=0, x=0)\n",
    "    \n",
    "def inputuji():\n",
    "    global fileuji\n",
    "    fileuji = filedialog.askopenfilename(initialdir='C:/Tutorial',\n",
    "                                          title=\"Select A File\",\n",
    "                                          filetype=((\"xlsx files\", \"*.xlsx\"), (\"all files\", \"*.*\")))\n",
    "    \n",
    "    styl.configure(\"ye.TLabel\", foreground=\"DeepSkyBlue\",background=\"aliceblue\")\n",
    "    datujis = tk.LabelFrame(root, text=\"Selected Data Uji\" ,bd =0\n",
    "                          ,bg ='aliceblue', fg = 'DeepSkyBlue')\n",
    "    datujis.place(height=45, width=800, y=230, x=5)\n",
    "    datujilabel = ttk.Label(datujis, text=fileuji,style=\"ye.TLabel\")\n",
    "    datujilabel.place(y=0, x=0)\n",
    "    datuji.configure(text=fileuji)\n",
    "    myFont = font.Font(family='Calibri', size=12, weight='bold')\n",
    "    datujis['font']=myFont\n",
    "    datujilabel['font']=myFont\n",
    "    menubar.entryconfig(\"Klasifikasi Naive Bayes\", state=\"normal\")\n",
    "    if fileuji==\"\":\n",
    "        datujilabel.configure(text=\"Tidak ada data\")\n",
    "    #sub_nevbayes.entryconfig(3, label = fileuji)\n",
    "\n",
    "def converduji():\n",
    "    global conuj\n",
    "    conuj = pd.DataFrame({\n",
    "    'komentar': komentarasli,\n",
    "    'label': labeld,\n",
    "    'komentar_casefolding' : komcasefold,\n",
    "    'komentar_cleaning': output['komentar'], \n",
    "    'komentar_tokenize': review['komentar_token'],\n",
    "    'komentar_stopword': review['komentar_token_stopwords'],\n",
    "    'komentar_mormalisasi': review['komentar_normalisasi'],\n",
    "    'komentar_stemmed': review['komentar_stemmed']\n",
    "    })\n",
    "    styl.configure(\"ye.TLabel\", foreground=\"DeepSkyBlue\",background=\"aliceblue\")\n",
    "    datujis = tk.LabelFrame(root, text=\"Selected Data Uji\" ,bd =0\n",
    "                          ,bg ='aliceblue', fg = 'DeepSkyBlue')\n",
    "    datujis.place(height=45, width=800, y=230, x=5)\n",
    "    datujilabel = ttk.Label(datujis, text=\"Data Uji Hasil Preprocessing\",style=\"ye.TLabel\")\n",
    "    datujilabel.place(y=0, x=0)\n",
    "    myFont = font.Font(family='Calibri', size=12, weight='bold')\n",
    "    datujis['font']=myFont\n",
    "    datujilabel['font']=myFont\n",
    "    menubar.entryconfig(\"Klasifikasi Naive Bayes\", state=\"normal\")\n",
    "    sub_nevbayes.entryconfig(4, label = \"Selected Data Uji\")\n",
    "    \n",
    "def showconuji():\n",
    "    df = conuj\n",
    "    newindow = Toplevel(root)\n",
    "    #newindow.title(fileuji)\n",
    "    newindow.geometry('720x400')\n",
    "    newindow.configure(bg=\"aliceblue\")\n",
    "    newindow.state(\"normal\")\n",
    "    f2 = Frame(newindow, height=200, width=300) \n",
    "    f2.pack(fill=BOTH,expand=1)\n",
    "    table = Table(f2, dataframe=df,read_only=True)\n",
    "    table.show()\n",
    "        \n",
    "def showdatuji():\n",
    "    global filedata_uji\n",
    "    filedata_uji = r\"{}\".format(datuji['text'])\n",
    "    review = pd.read_excel(filedata_uji)\n",
    "    df = review[['komentar','label','komentar_token','komentar_token_stopwords','komentar_normalisasi','komentar_stemmed']]\n",
    "    newindow = Toplevel(root)\n",
    "    newindow.title(fileuji)\n",
    "    newindow.geometry('720x400')\n",
    "    newindow.configure(bg=\"aliceblue\")\n",
    "    newindow.state(\"normal\")\n",
    "    f2 = Frame(newindow, height=200, width=300) \n",
    "    f2.pack(fill=BOTH,expand=1)\n",
    "    table = Table(f2, dataframe=df,read_only=True)\n",
    "    table.show()\n",
    "\n",
    "\n",
    "    \n",
    "class Model:\n",
    "    def __init__(self, prob_c0, prob_c1, prob_w_c0, prob_w_c1):\n",
    "        self.prob_c0 = prob_c0\n",
    "        self.prob_c1 = prob_c1\n",
    "        self.prob_w_c0 = prob_w_c0\n",
    "        self.prob_w_c1 = prob_w_c1\n",
    "def traindata(t):\n",
    "    #x_train = []\n",
    "    #y_train = []\n",
    "    #if t.endswith('.xlsx'):\n",
    "    #t2 = r\"{}\".format(t['text'])\n",
    "    \"\"\"\n",
    "    if t == filedatlatih:\n",
    "        train_dokumen = pd.read_excel(t)\n",
    "    else:\n",
    "        train_dokumen = conlat\n",
    "    \"\"\"\n",
    "    train_dokumen = pd.read_excel(t)\n",
    "    #train_dokumen.drop([\"no\", \"nama\",\"komentar\", \"tanggal scraping (17-02-2021)\", \"komentar_token\",\"komentar_token_stopwords\", \"komentar_normalisasi\"], axis = 1, inplace = True) \n",
    "    # mengganti label menjadi angka\n",
    "    train_dokumen['label'] = train_dokumen['label'].map({'positif':1 , 'negatif':0})\n",
    "    df = train_dokumen[['komentar_stemmed','label']]\n",
    "    # hapus karakter\n",
    "    df['komentar_stemmed'] = df['komentar_stemmed'].str.replace(\"[^a-zA-Z#]\", \" \")\n",
    "    x_train_array = df.values\n",
    "    x_train = x_train_array[:,0]\n",
    "    y_train = x_train_array[:,1]\n",
    "    # x_train merupakan list dokumen yang dijadikan training data\n",
    "    # n merupakan banyak kata yang ingin ada di dalam vocabulary\n",
    "        \n",
    "    \n",
    "    # menghitung frekuensi setiap kata\n",
    "    from nltk.tokenize import word_tokenize\n",
    "    \n",
    "    titles = x_train\n",
    "    freq = {}\n",
    "    for t in titles:\n",
    "        tokens = word_tokenize(t)\n",
    "        for w in tokens:\n",
    "            if w in freq:\n",
    "                freq[w] += 1\n",
    "            else:\n",
    "                freq[w] = 1\n",
    "    \n",
    "    # mengurutkan kata berdasarkan frekuensinya\n",
    "    sorted_freq = {key: values for key, values in sorted(freq.items(), key=lambda e: e[1], reverse=True)}\n",
    "    \n",
    "    # mengambil n kata dengan frekuensi terbesar untuk dijadikan vocabulary\n",
    "    global vocab\n",
    "    vocab = list(sorted_freq)[:1000]\n",
    "    \n",
    "    n_doc0 = list(y_train).count(0)\n",
    "    n_doc1 = list(y_train).count(1)\n",
    "    \n",
    "    \n",
    "    freq_0 = {}\n",
    "    freq_1 = {}\n",
    "\n",
    "    for i in range(len(x_train)):\n",
    "        tokens = word_tokenize(x_train[i])\n",
    "\n",
    "        # jika judul ke-i termasuk dalam kelas 0\n",
    "        if y_train[i] == 0:\n",
    "            for w in tokens:\n",
    "                if w in freq_0:\n",
    "                    freq_0[w] += 1\n",
    "                else:\n",
    "                    freq_0[w] = 1\n",
    "\n",
    "        # jika judul ke-i termasuk dalam kelas 1\n",
    "        else:\n",
    "            for w in tokens:\n",
    "                if w in freq_1:\n",
    "                    freq_1[w] += 1\n",
    "                else:\n",
    "                    freq_1[w] = 1\n",
    "    global fre\n",
    "    fre = {key: values for key, values in sorted(freq_1.items(), key=lambda e: e[1], reverse=True)}\n",
    "\n",
    "    global fre1\n",
    "    fre1 = {key: values for key, values in sorted(freq_0.items(), key=lambda e: e[1], reverse=True)}\n",
    "    \n",
    "    k = pd.DataFrame({\"positif\":fre,\"negatif\":fre1})\n",
    "    karray = k.values\n",
    "    koskatneg = karray[:,1]\n",
    "    koskatpos = karray[:,0]\n",
    "    koskats = k.index\n",
    "    global koskatable\n",
    "    koskatable = pd.DataFrame({\"Kosakata\":koskats,\"Negatif\":koskatneg,\"Positif\":koskatpos})\n",
    "    koskatable = koskatable.fillna(0)\n",
    "    \n",
    "    \n",
    "    n_vocab0 = 0\n",
    "    n_vocab1 = 0\n",
    "    for w in vocab:\n",
    "    # jika kata w muncul di kelas 0\n",
    "        if w in freq_0:\n",
    "            n_vocab0 += freq_0[w]\n",
    "    # jika kata w muncul di kelas 1\n",
    "        if w in freq_1:\n",
    "            n_vocab1 += freq_1[w]    \n",
    "    \n",
    "    # menghitung banyak dokumen yang masuk ke setiap kelas di data training\n",
    "    #n_doc0, n_doc1 = kelas_dokumen(y_train)\n",
    "    \n",
    "    # menghitung banyak dokumen pada data training\n",
    "    global n_doc\n",
    "    n_doc = len(x_train)\n",
    "    \n",
    "    # menghitung kemunculan setiap kata di setiap kelas pada data training\n",
    "    #freq_0, freq_1 = frekuensikata(x_train, y_train)\n",
    "        \n",
    "    # menghitung banyak kata yang muncul di setiap kelas yang termasuk dalam vocabulary\n",
    "    #n_vocab0, n_vocab1 = kelaskosakata(freq_0, freq_1, vocab)\n",
    "    \n",
    "    # menghitung estimasi\n",
    "    # probabilitas prior kelas 0\n",
    "    global prob_c0\n",
    "    prob_c0 = n_doc0/n_doc\n",
    "\n",
    "    # probabilitas prior kelas 1\n",
    "    global prob_c1\n",
    "    prob_c1 = n_doc1/n_doc\n",
    "    \n",
    "    # probabilitas kondisional\n",
    "    global prob_w_c0\n",
    "    global prob_w_c1\n",
    "    prob_w_c0 = {}\n",
    "    prob_w_c1 = {}\n",
    "\n",
    "    for w in vocab:\n",
    "        # jika kata w muncul di kelas 0\n",
    "        if w in freq_0:\n",
    "            prob_w_c0[w] = (freq_0[w]+1)/(n_vocab0+len(vocab))\n",
    "        else:\n",
    "            prob_w_c0[w] = 1/(n_vocab0+len(vocab))\n",
    "\n",
    "        # jika kata w muncul di kelas 1\n",
    "        if w in freq_1:\n",
    "            prob_w_c1[w] = (freq_1[w]+1)/(n_vocab1+len(vocab))\n",
    "        else:\n",
    "            prob_w_c1[w] = 1/(n_vocab1+len(vocab))            \n",
    "            \n",
    "    return df,x_train,y_train,vocab,n_doc0,n_doc1,freq_0,freq_0,n_vocab0, n_vocab1, prob_c0, prob_c1, prob_w_c0, prob_w_c1\n",
    "    \n",
    "    \n",
    "def training(x_train, y_train, nVocab, boolSmoothing):\n",
    "    \n",
    "    import pandas as pd\n",
    "    \n",
    "    # membuat vocab\n",
    "    vocab\n",
    "    \n",
    "    # melakukan estimasi\n",
    "    boolSmoothing = prob_c0, prob_c1, prob_w_c0, prob_w_c1\n",
    "    model = Model(prob_c0, prob_c1, prob_w_c0, prob_w_c1)\n",
    "    \n",
    "    return model\n",
    "\n",
    "def testdata(test, model):\n",
    "    #if test.endswith('.xlsx'):\n",
    "    #test2 = r\"{}\".format(test['text'])\n",
    "    \"\"\"\n",
    "    if test==filedatuji:\n",
    "        uji_dokumen = pd.read_excel(test)\n",
    "    else:\n",
    "        uji_dokumen = conuj\n",
    "    \"\"\"\n",
    "    uji_dokumen = pd.read_excel(test)\n",
    "    showdatest = pd.read_excel(test)\n",
    "    #uji_dokumen.drop([\"no\", \"nama\",\"komentar\", \"tanggal scraping (17-02-2021)\", \"komentar_token\",\"komentar_token_stopwords\", \"komentar_normalisasi\"], axis = 1, inplace = True) \n",
    "    uji_dokumen['label'] = uji_dokumen['label'].map({'positif':1 , 'negatif':0})\n",
    "    uji_dokumen = uji_dokumen[['komentar_stemmed','label']]\n",
    "    uji_dokumen['komentar_stemmed'] = uji_dokumen['komentar_stemmed'].str.replace(\"[^a-zA-Z#]\", \" \")\n",
    "    x_test_array = uji_dokumen.values\n",
    "    x_test = x_test_array[:,0]\n",
    "    y_test = x_test_array[:,1]\n",
    "    global datest\n",
    "    datest = showdatest['komentar']\n",
    "    from nltk.tokenize import word_tokenize\n",
    "    \n",
    "    y = []\n",
    "\n",
    "    for t in x_test:\n",
    "        tokens = word_tokenize(t)\n",
    "        # probabilitas prior\n",
    "        p0 = model.prob_c0\n",
    "        ask1 = model.prob_c1\n",
    "        p1 = model.prob_c1\n",
    "    \n",
    "\n",
    "        # menghitung probabilitas title t masuk ke kelas 0 dan kelas 1\n",
    "        for w in tokens:\n",
    "            if w in model.prob_w_c0:\n",
    "                p0 = p0 * model.prob_w_c0[w]\n",
    "\n",
    "            if w in model.prob_w_c1:\n",
    "                p1 = p1 * model.prob_w_c1[w]\n",
    "        #print (p0,p1)\n",
    "        # penentuan most likely class\n",
    "        if p0 > p1:\n",
    "            y.append(0)\n",
    "        else:\n",
    "            y.append(1)\n",
    "\n",
    "    return y,y_test,x_test\n",
    "\n",
    "def conf_matrix(y_real, y_predict, printMatrix):\n",
    "    \n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "    \n",
    "    tp0 = 0\n",
    "    fp0 = 0\n",
    "    tn0 = 0\n",
    "    fn0 = 0\n",
    "    tp1 = 0\n",
    "    fp1 = 0\n",
    "    tn1 = 0\n",
    "    fn1 = 0\n",
    "\n",
    "    for i in range(len(y_real)):\n",
    "        # true positive\n",
    "        if (y_real[i] == 1) & (y_predict[i] == 1):\n",
    "            tn0 += 1\n",
    "            tp1 += 1\n",
    "\n",
    "        # false positive\n",
    "        elif (y_real[i] == 0) & (y_predict[i] == 1):\n",
    "            fn0 += 1\n",
    "            fp1 += 1\n",
    "\n",
    "        # true negative\n",
    "        elif (y_real[i] == 0) & (y_predict[i] == 0):\n",
    "            tp0 += 1\n",
    "            tn1 += 1\n",
    "\n",
    "        # false negative\n",
    "        elif (y_real[i] == 1) & (y_predict[i] == 0):\n",
    "            fp0 += 1\n",
    "            fn1 += 1\n",
    "            \n",
    "    if printMatrix:\n",
    "        # kontingensi tabel untuk kelas 0\n",
    "        \"\"\"\n",
    "        plt.figure(figsize=(4,4))\n",
    "        sns.heatmap([[tn0,fp0],[fn0,tp0]], annot=True, fmt='d', xticklabels=['false', 'true'],\n",
    "                    yticklabels=['false', 'true'], cmap=plt.cm.Blues, cbar=False)\n",
    "        plt.title(\"Class 0's Confusion Matrix\")\n",
    "        plt.xlabel('Predicted Label')\n",
    "        plt.ylabel('True Label')\n",
    "        plt.show()\n",
    "        \"\"\"\n",
    "        \n",
    "        # kontingensi tabel untuk kelas 1\n",
    "        plt.figure(figsize=(6,6))\n",
    "        global hitmap\n",
    "        hitmap = sns.heatmap([[tn1,fp1],[fn1,tp1]], annot=True, fmt='d', xticklabels=['negatif', 'positif'],\n",
    "                    yticklabels=['negatif', 'positif'], cmap=plt.cm.Blues, cbar=False)\n",
    "        plt.title(\"Confusion Matrix\\n0 = negatif, 1 = positif\")\n",
    "        plt.xlabel('Data Prediksi')\n",
    "        plt.ylabel('Data Aktual')\n",
    "        #plt.labels = ['d','whjat','ksaoks']\n",
    "        #plt.show()\n",
    "        #global showplt\n",
    "        #showplt = plt.show()\n",
    "        #showplt\n",
    "        \n",
    "        global trueneg1\n",
    "        trueneg1=tn1\n",
    "        global falsepos1\n",
    "        falsepos1=fp1\n",
    "        global falseneg1\n",
    "        falseneg1=fn1\n",
    "        global truepos1\n",
    "        truepos1=tp1\n",
    "        \"\"\"\n",
    "        figure\n",
    "        figure = plt.figure(figsize=(6,6))\n",
    "        ax = figure.subplots()\n",
    "        conmat = pd.crosstab([[tn1,fp1],[fn1,tp1]], rownames = ['actual'], colnames = ['predicted'])\n",
    "        sns.heatmap(conmat, square=True, cbar=False, ax=ax)\n",
    "        \"\"\"\n",
    "    return (tp0, fp0, tn0, fn0), (tp1, fp1, tn1, fn1)\n",
    "\"\"\"\n",
    "def init_gui(root, update_function: Callable) ->FigureCanvasTkAgg:\n",
    "    def event_key_press(event):\n",
    "        print(\"you pressed {}\".format(event.key))\n",
    "        update_function()\n",
    "        key_press_handler(event, canvas)\n",
    "\n",
    "    # create empty figure and draw\n",
    "    init_figure = create_figure()\n",
    "    canvas = FigureCanvasTkAgg(init_figure, master=root)\n",
    "    canvas.draw()\n",
    "    canvas.get_tk_widget().pack(side=tkinter.TOP, fill=tkinter.BOTH, expand=1)\n",
    "    # call key press event\n",
    "    canvas.mpl_connect(\"key_press_event\", event_key_press)\n",
    "    return canvas\n",
    "\n",
    "def redraw_figure():\n",
    "    figure = create_figure()\n",
    "    canvas.figure = figure\n",
    "    canvas.draw\n",
    "    \n",
    "sns.set()\n",
    "canvas = init_gui(root, update_function=redraw_figure)\n",
    "\"\"\"\n",
    "\n",
    "def calc_metric(confMatrix0, confMatrix1):\n",
    "    \n",
    "    import pandas as pd\n",
    "    tp0, fp0, tn0, fn0 = confMatrix0\n",
    "    tp1, fp1, tn1, fn1 = confMatrix1\n",
    "    \n",
    "    # akurasi\n",
    "    accuracy0 = (tp0+tn0)/(tp0+fp0+fn0+tn0)\n",
    "    accuracy1 = (tp1+tn1)/(tp1+fp1+fn1+tn1)\n",
    "    \n",
    "    global accurate\n",
    "    accurate = accuracy1\n",
    "\n",
    "    # presisi\n",
    "    precision0 = tp0/(tp0+fp1)\n",
    "    precision1 = tp1/(tp1+fp0)\n",
    "    \n",
    "    # recall\n",
    "    recall0 = tp0/(tp0+fn1)\n",
    "    recall1 = tp1/(tp1+fn0)\n",
    "\n",
    "    # f1-measure\n",
    "    #f1_0 = (2*precision0*recall0)/(precision0+recall0)\n",
    "    #f1_1 = (2*precision1*recall1)/(precision1+recall1)\n",
    "    \n",
    "    # micro-averaging\n",
    "    tp_micro = tp0 + tp1\n",
    "    fp_micro = fp0 + fp1\n",
    "    tn_micro = tn0 + tn1\n",
    "    fn_micro = fn0 + fn1\n",
    "    \n",
    "    #theaccurate\n",
    "    global akurasi\n",
    "    akurasi = (tp1+tn0)/(tp1+tn0+fp1+fn0)\n",
    "    global presisi\n",
    "    presisi = tp1/(fp1+tp1)*100\n",
    "    global recall\n",
    "    recall = tp1/(fn0+tp1)*100\n",
    "    \n",
    "    accuracy_micro = (tp_micro+tn_micro)/(tp_micro+fp_micro+fn_micro+tn_micro)\n",
    "    precision_micro = (tp_micro)/(tp_micro+fp_micro)\n",
    "    recall_micro = (tp_micro)/(tp_micro+fn_micro)\n",
    "    f1_micro = (2 * precision_micro * recall_micro)/(precision_micro + recall_micro)\n",
    "    \n",
    "    # macro-averaging\n",
    "    accuracy_macro = (accuracy0+accuracy1)/2\n",
    "    precision_macro = (precision0+precision1)/2\n",
    "    recall_macro = (recall0+recall1)/2\n",
    "    #f1_macro = (f1_0+f1_1)/2\n",
    "    global eval_df\n",
    "    \"\"\"\n",
    "    eval_df = pd.DataFrame({'metriks evaluasi': ['akurasi','presisi','recall'], #'F1-measure'],\n",
    "                            'hasil': [(\"%.0f%%\" %(accuracy1*100)),\n",
    "                                        (\"%.0f%%\" %(precision1*100)),\n",
    "                                        (\"%.0f%%\" %(recall1*100))]})\n",
    "                            #, precision1, recall1]}) #f1_1]})\n",
    "                            #'micro': [accuracy_micro, precision_micro, recall_micro, f1_micro],\n",
    "                            #'macro': [accuracy_macro, precision_macro, recall_macro, f1_macro]})\n",
    "    #print(eval_df)\n",
    "    #['akurasi (tingkat kebenaran antara nilai predilsi dengan nilai aktual)', \n",
    "    #'presisi (tingkat ketepatan informasi dari pengguna dengan jawaban sistem)', \n",
    "    #'recall (tingkat keberhasilan sistem dalam menemukan kembali sebuah sistem)'],\n",
    "    \"\"\"\n",
    "    eval_df = pd.DataFrame({'metriks evaluasi': ['akurasi','presisi','recall'],\n",
    "                            'positif': [(\"%.0f%%\" %(accuracy1*100)),\n",
    "                                        (\"%.0f%%\" %(precision1*100)),\n",
    "                                        (\"%.0f%%\" %(recall1*100))],\n",
    "                            'negatif': [(\"%.0f%%\" %(accuracy0*100)), \n",
    "                                        (\"%.0f%%\" %(precision0*100)), \n",
    "                                        (\"%.0f%%\" %(recall0*100))],\n",
    "                            'hasil rata': [(\"%.0f%%\" %(accuracy_macro*100)), \n",
    "                                        (\"%.0f%%\" %(precision_macro*100)), \n",
    "                                        (\"%.0f%%\" %(recall_macro*100))]})\n",
    "    \n",
    "\n",
    "def evaluation(y_real, y_predict, printMatrix):\n",
    "    \n",
    "    # membuat 2 kontingensi tabel\n",
    "    confMatrix0, confMatrix1 = conf_matrix(y_real, y_predict, printMatrix)\n",
    "    \n",
    "    # menghitung 4 metrik evaluasi untuk setiap kelas\n",
    "    calc_metric(confMatrix0, confMatrix1)\n",
    "#conf_matrix(y_real, y_predict, printMatrix)\n",
    "\n",
    "def tren():\n",
    "    filedatlatih = r\"{}\".format(datlatih['text'])\n",
    "    #review = pd.read_excel(filedatlatih)\n",
    "    filedatuji = r\"{}\".format(datuji['text'])\n",
    "    #review = pd.read_excel(filedatlatih)\n",
    "    #data_latih = option_1.get()\n",
    "    #data_uji = option_2.get()\n",
    "    #df, x_train,y_train,vocab,n_doc0,n_doc1,freq_0, freq_1,n_vocab0, n_vocab1, prob_c0, prob_c1, prob_w_c0, prob_w_c1  = traindata(data_latih)\n",
    "    df, x_train,y_train,vocab,n_doc0,n_doc1,freq_0, freq_1,n_vocab0, n_vocab1, prob_c0, prob_c1, prob_w_c0, prob_w_c1  = traindata(filedatlatih)#(filedatlatih)\n",
    "    \"\"\"\n",
    "    if filedatlatih==\"\":\n",
    "        df, x_train,y_train,vocab,n_doc0,n_doc1,freq_0,freq_1,n_vocab0, n_vocab1, prob_c0, prob_c1, prob_w_c0, prob_w_c1  = traindata(conlat)\n",
    "    else:\n",
    "        df,x_train,y_train,vocab,n_doc0,n_doc1,freq_0,freq_1,n_vocab0, n_vocab1, prob_c0, prob_c1, prob_w_c0, prob_w_c1  = traindata(filedatlatih)\n",
    "    \"\"\"\n",
    "    nVocab = 0\n",
    "    global dokupos\n",
    "    dokupos=n_doc1\n",
    "    global dokuneg\n",
    "    dokuneg=n_doc0\n",
    "    global x_tren\n",
    "    x_tren = x_train\n",
    "    global katapos\n",
    "    katapos=n_vocab1\n",
    "    global kataneg\n",
    "    kataneg=n_vocab0\n",
    "    datapredict = training(x_train, y_train, nVocab, True)\n",
    "    \"\"\"\n",
    "    if filedatuji==\"\":\n",
    "        hasil_klasifikasi,y_test,x_test = testdata(conuj, datapredict)\n",
    "    else:\n",
    "        hasil_klasifikasi,y_test,x_test = testdata(filedatuji, datapredict)\n",
    "    \"\"\"\n",
    "    hasil_klasifikasi,y_test,x_test = testdata(filedatuji, datapredict)\n",
    "    #hasil_klasifikasi,y_test,x_test = testdata(data_uji, datapredict)#testdata(\"stopworduji.xlsx\", datapredict)\n",
    "    evaluation(y_test, hasil_klasifikasi, True)\n",
    "    #print (x_train)\n",
    "    #print(\"kosakata\",vocab)\n",
    "    #print(\"banyak dokumen\",n_doc0,n_doc1)\n",
    "    #print(\"banyak frekuensi\",freq_0,freq_0)\n",
    "    #print(\"banyak frekuensi\",n_vocab0, n_vocab1)\n",
    "    #print(\"probabilitas\",prob_c0, prob_c1, prob_w_c0, prob_w_c1)\n",
    "    probnegpos = pd.DataFrame({'Negatif':prob_w_c0 , 'Positif' : prob_w_c1})#({'Be':vocab})\n",
    "    print (probnegpos)\n",
    "    arrayprob = probnegpos.values\n",
    "    neg_arrayp = arrayprob[:,0]\n",
    "    pos_arrayp = arrayprob[:,1]\n",
    "    \n",
    "    global resfrektab\n",
    "    resfrektab = pd.DataFrame({'Prob negatif':prob_w_c0 , 'Prob positif' : prob_w_c1})\n",
    "                               #'Frek kata negatif':freq_0,'Frek kata positif':freq_1,\n",
    "                               #({'Dokumen negatif': [n_doc0],\n",
    "                               #'Dokumen positif': [n_doc1],\n",
    "                               #'Frekuensi kata negatif':[freq_0],\n",
    "                               #'Frekuensi kata positif':[freq_1]})\n",
    "                        \n",
    "    global vofrek\n",
    "    vofrek = pd.DataFrame({\"negatif\":fre, \"positif\":fre1})\n",
    "                        \n",
    "    global dataktab\n",
    "    probnegpose = pd.DataFrame({'Data_prediksi':y_test , 'Data_aktual' : hasil_klasifikasi})#({'Be':vocab})\n",
    "    dataktual = probnegpose['Data_aktual'].map({1:'positif' , 0:'negatif'})\n",
    "    datapredic = probnegpose['Data_prediksi'].map({1:'positif' , 0:'negatif'})\n",
    "    dataktab = pd.DataFrame({'Data test':datest, 'Data aktual(Sebelum Diklasifikasi)':datapredic, 'Data prediksi NBC(Sesudah Diklasifikasi)':dataktual})\n",
    "    dataktab\n",
    "    \n",
    "    global koskatabel\n",
    "    koskatabel = pd.DataFrame({'Kosakata':vocab,'Probabilitas negatif':neg_arrayp, 'Probabilitas positif':pos_arrayp})\n",
    "    \n",
    "\n",
    "    confmat = Toplevel(root)\n",
    "    teksi = \"Confusion Matrix : \"\n",
    "    teksa = (fileuji)\n",
    "    global teksb\n",
    "    teksb = teksi+teksa\n",
    "    confmat.title(teksb)\n",
    "    confmat.geometry('350x350')\n",
    "    confmat.state(\"normal\")\n",
    "    confmat.configure(bg=\"white\")\n",
    "    #label = Label(confmat, text = \"chigga\")\n",
    "    #label.place(x=5, y=150)\n",
    "    def init_gui(confmat, update_function: Callable) ->FigureCanvasTkAgg:\n",
    "        def event_key_press(event):\n",
    "            print(\"you pressed {}\".format(event.key))\n",
    "            update_function()\n",
    "            key_press_handler(event, canvas)\n",
    "\n",
    "        # create empty figure and draw\n",
    "        init_figure = create_figure()\n",
    "        canvas = FigureCanvasTkAgg(init_figure, master=confmat)\n",
    "        canvas.draw()\n",
    "        canvas.get_tk_widget().pack(side=tk.TOP, fill=tk.BOTH, expand=6)\n",
    "        # call key press event\n",
    "        canvas.mpl_connect(\"key_press_event\", event_key_press)\n",
    "        return canvas\n",
    "\n",
    "    def create_figure() ->Figure:\n",
    "        figure = Figure(figsize=(6, 6))\n",
    "        ax = figure.subplots()\n",
    "        sns.heatmap([[trueneg1,falsepos1],[falseneg1,truepos1]], annot=True, fmt='d', xticklabels=['negatif', 'positif'],\n",
    "                    yticklabels=['negatif', 'positif'], cmap=plt.cm.Blues, cbar=False,ax=ax)\n",
    "        ptitle = plt.title(\"Confusion Matrix\\n0 = negatif, 1 = positif\")\n",
    "        pxlabel = plt.xlabel('Data Prediksi')\n",
    "        pylabel = plt.ylabel('Data Aktual')\n",
    "        #plt.labels = ['d','whjat','ksaoks']\n",
    "        #plt.show()\n",
    "        hastes = \"Hasil akurasi confusion matrix : \"\n",
    "        acr = accurate*100\n",
    "        haskur = hastes+str(\"%.0f%%\" %(acr))\n",
    "        labelcm1 = Label(confmat,text=\"\",background=\"white\",height=2)\n",
    "        labelcm1.pack()\n",
    "        labelcm = Label(confmat,text=haskur, background=\"white\")\n",
    "        labelcm.place(x=10, y=8)\n",
    "        \n",
    "        Button(confmat, text = \"Hasil lainnya\", background = 'white',bd=0, fg='white',\n",
    "               anchor = \"ne\",command=shwrincian).place(x=255, y=8)\n",
    "        \n",
    "        #sn.heatmap(confusion_matrix, square=True, cbar=False, ax=ax)\n",
    "        return figure\n",
    "\n",
    "    def redraw_figure():\n",
    "        figure = create_figure()\n",
    "        ptitle = create_figure()\n",
    "        pxlabel = create_figure()\n",
    "        pylabel = create_figure()\n",
    "        canvas.figure = figure\n",
    "        canvas.draw\n",
    "    sns.set()\n",
    "    canvas = init_gui(confmat, update_function=redraw_figure)\n",
    "    menubar.entryconfig(\"Klasifikasi Manual\", state=\"normal\")\n",
    "    nevbayes.entryconfig('Hasil Bag Of Words', state=\"normal\")\n",
    "    nevbayes.entryconfig('Hasil Frekuensi', state=\"normal\")\n",
    "    nevbayes.entryconfig('Hasil Probabilitas', state=\"normal\")  \n",
    "    nevbayes.entryconfig('Hasil Data Aktual Prediksi', state=\"normal\")\n",
    "    nevbayes.entryconfig('Hasil Rincian', state=\"normal\")\n",
    "    nevbayes.entryconfig('Bantuan', state=\"normal\")\n",
    "    \n",
    "def shwrincian():\n",
    "    resconmat = Toplevel(root)\n",
    "    resconmat.title(teksb)\n",
    "    resconmat.geometry('460x170')\n",
    "    resconmat.configure(bg=\"aliceblue\")\n",
    "    resconmat.state(\"normal\")\n",
    "    f2resconmat = Frame(resconmat, height=400, width=400) \n",
    "    f2resconmat.pack(fill=BOTH,expand=1)\n",
    "    tableresconmat = Table(f2resconmat, dataframe=eval_df, read_only=True)\n",
    "    tableresconmat.columnconfigure(0,weight=3)\n",
    "    tableresconmat.columnconfigure(1,weight=1)\n",
    "    tableresconmat.show()\n",
    "\n",
    "def bow():\n",
    "    from sklearn.feature_extraction.text import CountVectorizer\n",
    "    vec = CountVectorizer()\n",
    "    count_kata = vec.fit_transform(x_tren)\n",
    "    vec.fit(x_tren)\n",
    "    vocabs = vec.get_feature_names ()\n",
    "    X_train_transformed  = vec.transform(x_tren)\n",
    "    X_train_transformed.toarray()\n",
    "    bags = pd.DataFrame(X_train_transformed.toarray()  , columns = vec.get_feature_names())\n",
    "    bow = Toplevel(root)\n",
    "    bow .title(\"Hasil Bag of Words\")\n",
    "    bow .geometry('350x350')\n",
    "    bow .configure(bg=\"aliceblue\")\n",
    "    bow .state(\"normal\")\n",
    "    bow2  = Frame(bow, height=400, width=400) \n",
    "    bow2.pack(fill=BOTH,expand=1)\n",
    "    tablebow = Table(bow2 , dataframe=bags, read_only=True)\n",
    "    tablebow.show()\n",
    "   \n",
    "def frekuensi():\n",
    "    resfrek = Toplevel(root)\n",
    "    resfrek .title(\"Hasil Frekuensi\")\n",
    "    resfrek .geometry('350x350')\n",
    "    resfrek .configure(bg=\"aliceblue\")\n",
    "    resfrek .state(\"normal\")\n",
    "    resfrekf2  = Frame(resfrek, height=400, width=400) \n",
    "    resfrekf2.pack(fill=BOTH,expand=1)\n",
    "    tableresfrek = Table(resfrekf2 , dataframe=koskatable, read_only=True)\n",
    "    tableresfrek.show()\n",
    "    \n",
    "def kosakata():\n",
    "    koskat = Toplevel(root)\n",
    "    teks = \"Hasil Probabilitas\"\n",
    "    koskat .title(teks)\n",
    "    koskat .geometry('350x350')\n",
    "    koskat .configure(bg=\"aliceblue\")\n",
    "    koskat .state(\"normal\")\n",
    "    koskatf2  = Frame(koskat, height=400, width=400) \n",
    "    koskatf2.pack(fill=BOTH,expand=1)\n",
    "    tablekoskat = Table(koskatf2 ,dataframe = koskatabel, read_only=True) #dataframe=vofrek, read_only=True) #koskatabel, read_only=True)\n",
    "    tablekoskat.show()\n",
    "    \n",
    "def dataktpred():\n",
    "    datakt = Toplevel(root)\n",
    "    tekd = \"Hasil data aktual dan prediksi menggunakan data uji : \"\n",
    "    teks = (fileuji)\n",
    "    teka = tekd+teks\n",
    "    datakt.title(teka)\n",
    "    datakt.geometry(\"350x350\")\n",
    "    datakt.configure(bg=\"aliceblue\")\n",
    "    datakt.state(\"normal\")\n",
    "    datakt2=Frame(datakt, height=400, width=400)\n",
    "    datakt2.pack(fill=BOTH,expand=1)\n",
    "    tabledatakt= Table(datakt2 , dataframe=dataktab, read_only=True)\n",
    "    tabledatakt.show()\n",
    "    \n",
    "def rincian():\n",
    "    df,x_train,y_train,vocab,n_doc0,n_doc1,freq_0,freq_1,n_vocab0, n_vocab1, prob_c0, prob_c1, prob_w_c0, prob_w_c1 = traindata(fileuji)\n",
    "    rincian = Toplevel(root)\n",
    "    rincian .title(\"Hasil rincian dari data\")\n",
    "    rincian .geometry('500x300')\n",
    "    rincian .configure(bg=None)\n",
    "    #rincian .state(\"normal\")\n",
    "    info = Label(rincian, text='Hasil rincian data')\n",
    "    #info2 = Label(rincian, text=filenamed)\n",
    "    info.pack()\n",
    "    #info2.pack()\n",
    "    \n",
    "    global tabs\n",
    "    tabs = ttk.Notebook(rincian)\n",
    "    first = ttk.Frame(tabs)\n",
    "    a = 5+1\n",
    "    tabs.add(first, text='Jumlah dokumen')\n",
    "    datname =\"Data Latih : \"\n",
    "    comb = datname+filenamed\n",
    "    combination = Label(first, text=comb)\n",
    "    combination.place(x = 5, y= 5)\n",
    "    \n",
    "    dokpos = Label(first, text=\"Dokumen positif :\")\n",
    "    o = Label(first,text= dokupos)\n",
    "    o.place(x = 115, y= 35)\n",
    "    dokpos.place(x = 5, y= 35)\n",
    "    \n",
    "    dokneg = Label(first, text=\"Dokumen negatif :\")#dokuneg)\n",
    "    dokneg.place(x = 5, y= 55)\n",
    "    i = Label(first,text= dokuneg)\n",
    "    i.place(x = 115, y= 55)\n",
    "    \n",
    "    datuji = \"Data Uji : \"\n",
    "    comb2 = datuji+fileuji\n",
    "    combi2 = Label(first, text=comb2)\n",
    "    combi2.place(x = 5, y= 85)\n",
    "    \n",
    "    dokujpos = Label(first, text=\"Dokumen positif :\")\n",
    "    o = Label(first,text= n_doc1)\n",
    "    o.place(x = 115, y= 115)\n",
    "    dokujpos.place(x = 5, y= 115)\n",
    "    \n",
    "    dokujneg = Label(first, text=\"Dokumen negatif :\")#dokuneg)\n",
    "    dokujneg.place(x = 5, y= 135)\n",
    "    i = Label(first,text= n_doc0)\n",
    "    i.place(x = 115, y= 135)\n",
    "    \n",
    "    second = ttk.Frame(tabs)\n",
    "    tabs.add(second, text='Jumlah kemunculan kata')\n",
    "    \n",
    "    datname =\"Data Latih : \"\n",
    "    comb = datname+filenamed\n",
    "    combination = Label(second, text=comb)\n",
    "    combination.place(x = 5, y= 5)\n",
    "    katpos = Label(second, text=\"Kemunculan kata positif :\")#, katapos)\n",
    "    katpos.place(x = 5, y= 35)\n",
    "    o2 = Label(second, text=katapos)\n",
    "    o2.place(x = 150, y= 35)\n",
    "    katpos = Label(second, text=\"Kemunculan kata negatif :\")#, kataneg)\n",
    "    katpos.place(x = 5, y= 55)\n",
    "    i2 = Label(second, text=kataneg)\n",
    "    i2.place(x = 150, y= 55)\n",
    "    datuji = \"Data Uji : \"\n",
    "    comb2 = datuji+fileuji\n",
    "    combi2 = Label(second, text=comb2)\n",
    "    combi2.place(x = 5, y= 85)\n",
    "    dokujpos = Label(second, text=\"Kemunculan kata positif :\")\n",
    "    o = Label(second,text= n_vocab1)\n",
    "    o.place(x = 150, y= 115)\n",
    "    dokujpos.place(x = 5, y= 115)\n",
    "    dokujneg = Label(second, text=\"Kemunculan kata negatif :\")#dokuneg)\n",
    "    dokujneg.place(x = 5, y= 135)\n",
    "    i = Label(second,text= n_vocab0)\n",
    "    i.place(x = 150, y= 135)\n",
    "    \n",
    "    global third\n",
    "    \"\"\"\n",
    "    third = ttk.Frame(tabs)\n",
    "    tabs.add(third, text=\"Klasifikasi manual\")\n",
    "    teks = Label(third, text=\"Input teks : \")\n",
    "    teks.place(x = 5, y= 15)    \n",
    "    enter = Entry(third, width = 65)\n",
    "    enter.place(x = 70, y= 15)\n",
    "    \n",
    "    submit = Button(third, text=\"Proses\", command = lambda : klasmanual2(enter))\n",
    "    submit.place(x = 5, y= 40)\n",
    "    \n",
    "    hasyl = \"Kalimat : \"\n",
    "    hasilprp = Label(third, text=hasyl)\n",
    "    hasilprp.place(x = 5, y = 65)\n",
    "    global haskmat\n",
    "    haskmat = Label(third, text = \"Tidak ada\")\n",
    "    haskmat.place(x=135, y=65)\n",
    "    \n",
    "    hasilprp = \"Hasil preprocessing : \"\n",
    "    hasilcombprp = Label(third, text = hasilprp)\n",
    "    hasilcombprp.place(x=5,y=85)\n",
    "    global prephas\n",
    "    prephas = Label(third, text = \"Tidak ada\")\n",
    "    prephas.place(x=135, y=85)\n",
    "    \n",
    "\n",
    "    probres = Label(third, text = \"Hasil klasifikasi : \")\n",
    "    probres.place(x=5, y=105)\n",
    "    global probhas\n",
    "    probhas = Label(third, text = \"Tidak ada\")\n",
    "    probhas.place(x=135, y=105)\n",
    "    \n",
    "    #submit2 = Button(third, text=\"Proses2\", command = lambda : update)\n",
    "    #submit2.place(x = 5, y= 140)\n",
    "    #return tabs,third\n",
    "    \"\"\"\n",
    "    fontstyle = (\"arial\",8,\"normal\")\n",
    "    \n",
    "    fourth = ttk.Frame(tabs)\n",
    "    tabs.add(fourth, text=\"Klasifikasi manual teks\")\n",
    "    teks = Label(fourth , text=\"Input teks : \")\n",
    "    teks.place(x = 5, y= 15)  \n",
    "    global enter\n",
    "    enter = Text(fourth , relief=GROOVE, width=55, height=5, wrap=WORD)\n",
    "    enter.place(x = 135, y= 15)\n",
    "    enter.configure(font = fontstyle)\n",
    "    \n",
    "    act = Button(fourth, text=\"Proses\", command = lambda : replace(enter))\n",
    "    act.place(x = 5, y= 70)\n",
    "    \n",
    "    outputeks = Label(fourth, text=\"Hasil preprocessing : \", anchor = 'w')\n",
    "    outputeks.place(x = 5, y= 115)\n",
    "    global outputw\n",
    "    outputw = Text(fourth, relief=GROOVE, background='#f0f0f0', width=55, height=5, wrap=WORD)\n",
    "    outputw.place(x = 135, y= 115)\n",
    "    outputw.configure(font = fontstyle)\n",
    "    \n",
    "    nbteks = Label(fourth, text=\"Hasil klasifikasi : \")\n",
    "    nbteks.place(x = 5, y= 200)\n",
    "    global nbhasil\n",
    "    nbhasil = Label(fourth, text =\"-\")\n",
    "    nbhasil.place(x = 135, y= 200)\n",
    "    \n",
    "    \"\"\"\n",
    "    fifth = ttk.Frame(tabs)\n",
    "    tabs.add(fifth, text=\"Probabilitas cheker\")\n",
    "    teks = Label(fifth, text=\"Input teks : \")\n",
    "    teks.place(x = 5, y= 15)    \n",
    "    enter = Entry(fifth, width = 65)\n",
    "    enter.place(x = 70, y= 15)\n",
    "    \n",
    "    submit = Button(fifth, text=\"Cek\", command = lambda : cheks(enter))\n",
    "    submit.place(x = 5, y= 40)\n",
    "    \n",
    "    outpud = Label(fifth, text=\"Hasil teks : \")\n",
    "    outpud.place(x = 5, y= 65)\n",
    "    global outpud2\n",
    "    outpud2 = Label(fifth, text=\"Tidak ada data\")\n",
    "    outpud2.place(x = 70, y = 65)\n",
    "    \n",
    "    third = ttk.Frame(tabs)\n",
    "    tabs.add(third, text='Hasil probabilitas prior')\n",
    "    katpos = Label(third, text=\"Kata yang mengandung positif :\")#, katapos)\n",
    "    katpos.place(x = 5, y= 15)\n",
    "    o3 = Label(third, text=katapos)\n",
    "    o3.place(x = 190, y= 15)\n",
    "    katpos = Label(third, text=\"Kata yang mengandung negatif :\")#, kataneg)\n",
    "    katpos.place(x = 5, y= 35)\n",
    "    i3 = Label(third, text=kataneg)\n",
    "    i3.place(x = 190, y= 35)\n",
    "    \"\"\"\n",
    "    tabs.pack(expand=1,fill=\"both\")\n",
    "    \n",
    "    \"\"\"\n",
    "    liststyl = Frame(rincian, bd=1, relief = 'sunken', background=\"white\")\n",
    "    liststyl.pack(padx=10, pady=10, fill=None, expand=False)\n",
    "    \n",
    "    listinfo = Listbox(liststyl, width=20, height=10, borderwidhth=0,\n",
    "                      highlightthickness=0, background=liststyle.cget(\"background\"))\n",
    "    vsb = Scrollbar(liststyl, orient=\"vertical\",command=listinfo.yview)\n",
    "    listinfo.configure(yscrollcommand=vsb)\n",
    "    vsb.pack(side=\"right\",fill=\"y\")\n",
    "    listinfo.pack(padx=10, pady=10, fill=\"both\", expand=True)\n",
    "    \n",
    "    for i in range(20):\n",
    "        listinfo.insert(\"end\", \"item #{}\". format(i))\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    info = Label(rincian, text='Hasil klasifikasi', anchor = 'e')\n",
    "    info.pack()\n",
    "    labrinci = LabelFrame(rincian, text='Hasil rincian dari data uji')#, padx = 150, pady = 20)#, anchor = 'e')\n",
    "    info.config(font = ('arial',14))\n",
    "    labrinci.pack(expand = 'yes', fill = 'both')\n",
    "    doc = ttk.Label(labrinci, text='Hasil jumlah dokumen =', width = 60)#, anchor = 'e')\n",
    "    doc.place(x = 5, y= 5)\n",
    "    docpos = ttk.Label(labrinci, text='Dokumen positif =')#, anchor = 'e')\n",
    "    docpos.place(x = 5, y= 15)#grid(row=7, column=0, padx=10, pady=15)#, sticky=N+W)\n",
    "    \n",
    "    labelteks = Label(rincian, text='Hasil klasifikasi', anchor = 'e')\n",
    "    labelteks.config(font=('arial', 10))\n",
    "    labelteks.pack()\n",
    "    canvase = Canvas(rincian, highlightthickness=0, width = 320, height = 290,  relief = 'ridge', bg=None, bd=2)\n",
    "    canvase.pack()\n",
    "   \n",
    "    ketrin = Label(rincian, text='Klasifikasi teks naivebayes', bg='#424242', fg='#9CB071')\n",
    "    ketrin.config(font=('helvetica', 14))\n",
    "    \n",
    "    #canvase.create_window(225, 25, window=file_frame)\n",
    "    dokumen = Label(rincian, text='Jumlah dokumen data') #anchor = 'e')\n",
    "    dokumenpos = Label(rincian, text='Dokumen positif = 0as0das') #anchor = 'e')\n",
    "    canvase.create_window(60, 40, window=dokumen)\n",
    "    canvase.create_window(60, 80, window=dokumenpos)\n",
    "    \"\"\"\n",
    "    #koskatf2  = Frame(koskat, height=400, width=400) \n",
    "    #koskatf2.pack(fill=BOTH,expand=1)\n",
    "    #tablekoskat = Table(koskatf2 , dataframe=koskatabel, read_only=True)\n",
    "    #tablekoskat.show()\n",
    "    \"\"\"\n",
    "    onfmat = Toplevel(root)\n",
    "    figure = Figure(figsize=(5, 4), dpi=100)\n",
    "    plot = figure.add_subplot(1, 1, 1)\n",
    "    canvas = FigureCanvasTkAgg(figure, onfmat)\n",
    "    canvas.get_tk_widget().grid(row=0, column=0)\n",
    "    #conftab.show()\n",
    "    \"\"\"\n",
    "def manual(train):\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "    from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory\n",
    "    import re \n",
    "    import string\n",
    "    from nltk.corpus import stopwords\n",
    "    \n",
    "    x_trains = [train]\n",
    "    #x_tests = [test]\n",
    "    #x_trains\n",
    "    \n",
    "    # casefolding\n",
    "\n",
    "    x_train_preprocess1 = []\n",
    "    #x_test_preprocess1 = []\n",
    "\n",
    "    for i in range(len(x_trains)):\n",
    "        x_train_preprocess1.append(x_trains[i].lower())\n",
    "    \n",
    "    #for i in range(len(x_tests)):\n",
    "        #x_test_preprocess1.append(x_tests[i].lower())\n",
    "    \n",
    "    # cleaning (hapus angka)\n",
    "    \n",
    "    x_train_preprocess2 = []\n",
    "    #x_test_preprocess2 = []\n",
    "\n",
    "    for i in range(len(x_train_preprocess1)):\n",
    "        x_train_preprocess2.append(re.sub(r\"\\d+\", \"\", x_train_preprocess1[i]))   \n",
    "    \n",
    "    #for i in range(len(x_test_preprocess1)):\n",
    "        #x_test_preprocess2.append(re.sub(r\"\\d+\", \"\", x_test_preprocess1[i]))\n",
    "        \n",
    "    # cleaning (hapus simbol)\n",
    "        \n",
    "    x_train_preprocess3 = []\n",
    "    #x_test_preprocess3 = []\n",
    "\n",
    "    for i in range(len(x_train_preprocess2)):\n",
    "        x_train_preprocess3.append(x_train_preprocess2[i].translate(str.maketrans(\"\",\"\",string.punctuation)))\n",
    "    \n",
    "    #for i in range(len(x_train_preprocess2)):\n",
    "        #x_test_preprocess3.append(x_test_preprocess2[i].translate(str.maketrans(\"\",\"\",string.punctuation)))\n",
    "        \n",
    "    # stopword\n",
    "    stop_factory = StopWordRemoverFactory()\n",
    "    more_stopword = ['aku','saya','dan','banyak']\n",
    "    data = stop_factory.get_stop_words()+more_stopword\n",
    "    \n",
    "    sw_remover = StopWordRemoverFactory().create_stop_word_remover()\n",
    "    x_train_preprocess4 = []\n",
    "    #x_test_preprocess4 = []\n",
    "\n",
    "    for i in range(len(x_train_preprocess3)):\n",
    "        x_train_preprocess4.append(sw_remover.remove(x_train_preprocess3[i]))\n",
    "    \n",
    "    #for i in range(len(x_test_preprocess3)):\n",
    "        #x_test_preprocess4.append(sw_remover.remove(x_test_preprocess3[i]))\n",
    "        \n",
    "    # normalisasi\n",
    "    \n",
    "    normalizad_word = pd.read_excel(\"normalisasi.xlsx\")\n",
    "\n",
    "    normalizad_word_dict = {}\n",
    "\n",
    "    for index, row in normalizad_word.iterrows():\n",
    "        if row[0] not in normalizad_word_dict:\n",
    "            normalizad_word_dict[row[0]] = row[1] \n",
    "\n",
    "    def normalized_term(document):\n",
    "        return [normalizad_word_dict[term] if term in normalizad_word_dict else term for term in document]\n",
    "    x_train_preprocess5 = normalized_term(x_train_preprocess4)\n",
    "    #x_test_preprocess5 = normalized_term(x_test_preprocess4)\n",
    "    \n",
    "    factory = StemmerFactory()\n",
    "    stemmer = factory.create_stemmer()\n",
    " \n",
    "    x_train_preprocess6 = []\n",
    "    #x_test_preprocess6 = []\n",
    "\n",
    "    for i in range(len(x_train_preprocess5)):\n",
    "        x_train_preprocess6.append(stemmer.stem(x_train_preprocess5[i]))\n",
    "    \n",
    "    #for i in range(len(x_test_preprocess5)):\n",
    "        #x_test_preprocess6.append(stemmer.stem(x_test_preprocess5[i]))\n",
    "        \n",
    "    return x_train_preprocess6\n",
    "                             \n",
    "def preprocessing(d):\n",
    "    import re\n",
    "    from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "    factory = StemmerFactory()\n",
    "    stemmer = factory.create_stemmer()\n",
    "\n",
    "    d = d.lower()     \n",
    "    d = re.sub(r'[^A-Za-z]', ' ', d)    \n",
    "    d = d.split()    \n",
    "    stoplist = (open('indo.txt', 'r').read().replace('\\n', ' ')).split(\" \")\n",
    "    d = [i for i in d if i not in stoplist]    \n",
    "    d = [i for i in d if len(i)>1]    \n",
    "    d = [stemmer.stem(i) for i in d]\n",
    "    str1 = \" \"\n",
    "    d = (str1.join(d))\n",
    "    return [d]\n",
    "    \n",
    "def testing2(testteks, model):\n",
    "    \n",
    "    from nltk.tokenize import word_tokenize\n",
    "    \n",
    "    y = []\n",
    "\n",
    "    for t in testteks:\n",
    "        tokens = word_tokenize(t)\n",
    "        # probabilitas prior\n",
    "        p0 = model.prob_c0\n",
    "        ask1 = model.prob_c1\n",
    "        p1 = model.prob_c1\n",
    "\n",
    "        # menghitung probabilitas title t masuk ke kelas 0 dan kelas 1\n",
    "        for w in tokens:\n",
    "            if w in model.prob_w_c0:\n",
    "                p0 = p0 * model.prob_w_c0[w]\n",
    "            if w in model.prob_w_c1:\n",
    "                p1 = p1 * model.prob_w_c1[w]\n",
    "        print (p0,p1)\n",
    "        # penentuan most likely class\n",
    "        if p0 > p1:\n",
    "            y.append(\"negatif\")\n",
    "        else:\n",
    "            y.append(\"positif\")\n",
    "\n",
    "    return max(p0,p1),y\n",
    "\n",
    "def cheks(key):\n",
    "    yoy = key.get()\n",
    "    teks = r\"{}\".format(yoy)\n",
    "    outpud2.config(text = teks)\n",
    "\n",
    "def klasmanual(entry1):\n",
    "    filedatlatih = r\"{}\".format(datlatih['text'])\n",
    "    #review = pd.read_excel(filedatlatih)\n",
    "    #filedatuji = r\"{}\".format(datuji['text'])\n",
    "    #review = pd.read_excel(filedatlatih)\n",
    "    df,x_train,y_train,vocab,n_doc0,n_doc1,freq_0,freq_1,n_vocab0, n_vocab1, prob_c0, prob_c1, prob_w_c0, prob_w_c1  = traindata(filedatlatih)\n",
    "    nVocab = 0\n",
    "    yoy = entry1.get()\n",
    "    teks = r\"{}\".format(yoy)\n",
    "    #eje = {(\"hasil dari data\",teks,\"memiliki nilai sebesar = \")}\n",
    "    eksts = preprocessing(teks)\n",
    "    model_preprocess6 = training(x_train, y_train, nVocab, True)\n",
    "    y_predict_preprocess6 = testing2(eksts, model_preprocess6)\n",
    "    labelhasil = Label(inputeks, text=\"hasil dari kalimat\", bg='#424242', fg='aliceblue')\n",
    "    labelhasil.config(font=('helvetica', 14))\n",
    "    labelhasil1 = Label(inputeks, text=teks, bg='#424242', fg='aliceblue', width = 450, height = 2)\n",
    "    labelhasil1.config(font=('helvetica', 14))\n",
    "    labelhasil2 = Label(inputeks, text=\"memiliki nilai sebesar\" ,bg='#424242', fg='aliceblue')\n",
    "    labelhasil2.config(font=('helvetica', 14))\n",
    "    labelhasil3 = Label(inputeks, text=y_predict_preprocess6 ,bg='#424242', fg='aliceblue',width = 450)\n",
    "    labelhasil3.config(font=('helvetica', 14))\n",
    "    canvas1.create_window(350, 198, window=labelhasil)\n",
    "    canvas1.create_window(350, 240, window=labelhasil1)\n",
    "    canvas1.create_window(350, 280, window=labelhasil2)\n",
    "    canvas1.create_window(350, 320, window=labelhasil3)\n",
    "    print (\"hasil dari data\",teks,\"memiliki nilai sebesar = \",y_predict_preprocess6)#,y_predict_preprocess6)\n",
    "\n",
    "def replace(w):\n",
    "    filedatlatih = r\"{}\".format(datlatih['text'])\n",
    "    df,x_train,y_train,vocab,n_doc0,n_doc1,freq_0,freq_1,n_vocab0, n_vocab1, prob_c0, prob_c1, prob_w_c0, prob_w_c1  = traindata(filedatlatih)\n",
    "    nVocab = 0\n",
    "    yoy = w.get(\"1.0\", END)\n",
    "    teks = r\"{}\".format(yoy)\n",
    "    eksts = preprocessing(teks)\n",
    "    theprep = ''.join(map(str,eksts))\n",
    "    preps = theprep.replace(\"!@#$\",\"\")\n",
    "    model_preprocess6 = training(x_train, y_train, nVocab, True)\n",
    "    y_predict_preprocess6 = testing2(eksts, model_preprocess6)\n",
    "    nbhasil.config(text = y_predict_preprocess6)\n",
    "    outputw.delete(\"1.0\", END)\n",
    "    outputw.insert(END, preps)\n",
    "    \n",
    "    if preps == \"\":\n",
    "        nbhasil.config(text = \"\")\n",
    "        \n",
    "def replace2(k):\n",
    "    yoy = k.get(\"1.0\", END)\n",
    "    teks = r\"{}\".format(yoy)\n",
    "    #eje = {(\"hasil dari data\",teks,\"memiliki nilai sebesar = \")}\n",
    "    eksts = preprocessing(teks)\n",
    "    theprep = ''.join(map(str,eksts))\n",
    "    preps = theprep.replace(\"!@#$\",\"\")\n",
    "    outpute.delete(\"1.0\", END)\n",
    "    outpute.insert(END, preps)\n",
    "    \n",
    "def klasmanual2(entry2):\n",
    "    filedatlatih = r\"{}\".format(datlatih['text'])\n",
    "    #review = pd.read_excel(filedatlatih)\n",
    "    #filedatuji = r\"{}\".format(datuji['text'])\n",
    "    #review = pd.read_excel(filedatlatih)\n",
    "    df,x_train,y_train,vocab,n_doc0,n_doc1,freq_0,freq_1,n_vocab0, n_vocab1, prob_c0, prob_c1, prob_w_c0, prob_w_c1  = traindata(filedatlatih)\n",
    "    nVocab = 0\n",
    "    yoy = entry2.get()\n",
    "    teks = r\"{}\".format(yoy)\n",
    "    #eje = {(\"hasil dari data\",teks,\"memiliki nilai sebesar = \")}\n",
    "    eksts = preprocessing(teks)\n",
    "    theprep = ''.join(map(str,eksts))\n",
    "    preps = theprep.replace(\"!@#$\",\"\")\n",
    "    model_preprocess6 = training(x_train, y_train, nVocab, True)\n",
    "    y_predict_preprocess6 = testing2(eksts, model_preprocess6)\n",
    "                    \n",
    "    haskmat.config(text = teks)\n",
    "    prephas.config(text = theprep)\n",
    "    probhas.config(text = y_predict_preprocess6)\n",
    "    \n",
    "    if theprep == \"\":\n",
    "        probhas.config(text = \"Kosong\")\n",
    "        \n",
    "    \"\"\"\n",
    "    hasyl = \"Kalimat : \"\n",
    "    hasyyl = hasyl+teks\n",
    "    hasilprp = Label(third, text=hasyl)\n",
    "    hasilprp.place(x = 5, y = 65)\n",
    "    haskmat = Label(third, text = teks)\n",
    "    haskmat.place(x=135, y=65)\n",
    "    \n",
    "    hasilprp = \"Hasil preprocessing : \"\n",
    "    hasilprp2 = \") adalah : \"\n",
    "    hasilprp3 = hasilprp+teks+hasilprp2\n",
    "    hasilcombprp = Label(third, text = hasilprp)\n",
    "    hasilcombprp.place(x=5,y=85)\n",
    "\n",
    "    prephas = Label(third, text = eksts)\n",
    "    prephas.place(x=135, y=85)\n",
    "    probres = Label(third, text = \"Hasil klasifikasi : \")\n",
    "    probres.place(x=5, y=105)\n",
    "    probhas = Label(third, text = y_predict_preprocess6)\n",
    "    probhas.place(x=135, y=105)\n",
    "    \"\"\"\n",
    "                    \n",
    "    \n",
    "    print (\"hasil dari data\",teks,\"memiliki nilai sebesar = \",y_predict_preprocess6)#,y_predict_preprocess6)\n",
    "\n",
    "def inputteks():\n",
    "    global inputeks\n",
    "    inputeks = Toplevel(root)\n",
    "    inputeks.title(\"Klasifikasi Manual\")\n",
    "    #inputeks.geometry('350x350')\n",
    "    inputeks.configure(bg=\"#424242\")\n",
    "    inputeks.state(\"normal\")\n",
    "    \"\"\"\n",
    "    menubar = Menu(inputeks)\n",
    "    inputeks.config(menu=menubar)\n",
    "    bantuan = Menu(inputeks, tearoff = 0)\n",
    "    menubar.add_cascade(label ='Bantuan', menu = bantuan, command = bantu) #state=tk.DISABLED) #state=tk.DISABLED)\n",
    "    bantuan.add_command(label = 'Info', command = inputteks)\n",
    "    \n",
    "    \n",
    "    # specify size of window.\n",
    "    inputeks.geometry(\"250x170\")\n",
    "  \n",
    "    # Create text widget and specify size.\n",
    "    T = Text(inputeks, height = 5, width = 52)\n",
    "  \n",
    "    # Create label\n",
    "    l = Label(inputeks, text = \"Fact of the Day\")\n",
    "    l.config(font =(\"Courier\", 14))\n",
    "  \n",
    "    Fact = A man can be arrested in\n",
    "    Italy for wearing a skirt in public\n",
    "  \n",
    "    # Create button for next text.\n",
    "    b1 = Button(inputeks, text = \"Next\", )\n",
    "  \n",
    "    # Create an Exit button.\n",
    "    b2 = Button(inputeks, text = \"Exit\",\n",
    "                command = inputeks.destroy) \n",
    "  \n",
    "    l.pack()\n",
    "    T.pack()\n",
    "    b1.pack()\n",
    "    b2.pack()\n",
    "  \n",
    "    # Insert The Fact.\n",
    "    T.insert(tk.END, Fact)\n",
    "    \"\"\"\n",
    "  \n",
    "    global canvas1\n",
    "    canvas1 = Canvas(inputeks, highlightthickness=0, width = 700, height = 400,  relief = 'ridge', bg=\"#424242\", bd=0)\n",
    "    canvas1.pack()\n",
    "\n",
    "    label1 = Label(inputeks, text='Klasifikasi teks naivebayes', bg='#424242', fg='aliceblue')\n",
    "    label1.config(font=('helvetica', 14))\n",
    "    canvas1.create_window(350, 25, window=label1)\n",
    "\n",
    "    label2 = Label(inputeks, text='Input kalimat:', bg='#424242', fg='aliceblue')\n",
    "    canvas1.create_window(350, 70, window=label2)\n",
    "    #global entry\n",
    "    entry1 = Entry(inputeks, width = 52, bd = 0, bg='darkgrey') #height = 5) \n",
    "    canvas1.create_window(350, 110, window=entry1)\n",
    "    \n",
    "    proses = Button(inputeks, text='Proses', bg='#424242', fg='aliceblue', command = lambda : klasmanual(entry1))\n",
    "    canvas1.create_window(350, 160, window=proses)\n",
    "    \n",
    "    label2['font']=myFont\n",
    "    proses['font']=myFont\n",
    "        \n",
    "\n",
    "    \n",
    "def bantu():\n",
    "    msg.showinfo('Info',\n",
    "                'Klasifikasi untuk teks\\nPengujian dilakukan dengan menggunakan data train serta menginputkan teks secara manual')\n",
    "def bantuconfmat():\n",
    "    msg.showinfo('Info',\n",
    "                'akurasi (tingkat kebenaran antara nilai predilsi dengan nilai aktual)\\npresisi (tingkat ketepatan informasi dari pengguna dengan jawaban sistem)\\nrecall (tingkat keberhasilan sistem dalam menemukan kembali sebuah sistem)')\n",
    "\"\"\"\n",
    "def getSquareRoot ():\n",
    "    \n",
    "    x1 = entry1.get()\n",
    "    \n",
    "    label3 = Label(inputeks, text= 'The Square Root of ' + x1 + ' is:',font=('helvetica', 10))\n",
    "    canvas1.create_window(200, 210, window=label3)\n",
    "    \n",
    "    label4 = Label(inputeks, text= float(x1)**0.5,font=('helvetica', 10, 'bold'))\n",
    "    canvas1.create_window(200, 230, window=label4)\n",
    "    \n",
    "    button1 = Button(text='Get the Square Root', command=getSquareRoot, bg='brown', fg='white', font=('helvetica', 9, 'bold'))\n",
    "    canvas1.create_window(200, 160, window=button1)\n",
    "\"\"\"\n",
    "def newtabel():\n",
    "    canvastab = Canvas(root, highlightthickness=0, width = 400, height = 300,  relief = 'ridge', bg=\"lightblue\", bd=0)\n",
    "    canvastab.pack()\n",
    "    click = Button(root, bg='aliceblue', anchor = \"e\", width = 60, height = 21, bd=0, command = lambda : canvastab.pack_forget()) #width = 200, height = 200)\n",
    "    clicke = Button(root, bg='navyblue', anchor = \"e\", width = 30, height = 21, bd=0, command = lambda : canvastab.pack_forget())\n",
    "    click.pack()\n",
    "    clicke.pack()\n",
    "    canvastab.create_window(20, 50, window=click)\n",
    "    #canvasyntkts.create_window(200, 150, window=clicke)\n",
    "\n",
    "#menu bar\n",
    "menubar = Menu(root)\n",
    "root.config(menu=menubar)\n",
    "file = Menu(menubar, tearoff = 0)\n",
    "menubar.add_cascade(label ='File', menu = file)\n",
    "#file.add_command(label ='New File', command = None)\n",
    "file.add_command(label ='Open File Data Preprocessing', command = File_dialog)\n",
    "file.add_command(label ='Open File Data Latih', command = inputlatih)\n",
    "file.add_command(label ='Open File Data Uji', command = inputuji)\n",
    "file.add_command(label ='Bantuan', command = helpp)\n",
    "#file.add_command(label ='Save', command = None)\n",
    "file.add_separator()\n",
    "file.add_command(label ='Exit', command = root.destroy)\n",
    "        \n",
    "edit = Menu(root, tearoff = 0)\n",
    "menubar.add_cascade(label ='Preprocessing', menu = edit, state=tk.DISABLED)\n",
    "edit.add_command(label ='Proses', command = prins)\n",
    "edit.add_command(label ='Show Data', command = showtabel1)\n",
    "edit.add_command(label ='Hasil Preprocessing', command = showtabel2)\n",
    "edit.add_separator()\n",
    "sub_menu = Menu(edit, tearoff=0)\n",
    "sub_menu.add_command(label = 'Proses Data Uji', command = converd)\n",
    "sub_menu.add_command(label = 'Show Data Uji', command = showcondat)\n",
    "sub_menu.add_command(label = 'Proses Data Latih', command = converduji)\n",
    "sub_menu.add_command(label = 'Show Data Latih', command = showconuji)\n",
    "#edit.add_cascade(label ='Apply', menu=sub_menu)\n",
    "edit.add_command(label ='Save Data', command = exportExcel)\n",
    "edit.entryconfig(2, state=DISABLED)\n",
    "edit.entryconfig(4, state=DISABLED)\n",
    "edit.entryconfig(5, state=DISABLED)\n",
    "\n",
    "nevbayes = Menu(root, tearoff=0)\n",
    "menubar.add_cascade(label ='Klasifikasi Naive Bayes', menu = nevbayes, state=tk.DISABLED) #state=tk.DISABLED)\n",
    "\"\"\"\n",
    "sub_nevbayes = Menu(nevbayes, tearoff = 0)\n",
    "option_1 = tk.StringVar()\n",
    "option_2 = tk.StringVar()\n",
    "sub_nevbayes.add_radiobutton(label=\"No Data\", variable=option_1, value=datlatih)\n",
    "sub_nevbayes.add_radiobutton(label=\"No Data\", variable=option_1)#, value=conlat)\n",
    "sub_nevbayes.add_separator()\n",
    "sub_nevbayes.add_radiobutton(label=\"No Data\",variable=option_2, value=datuji)\n",
    "sub_nevbayes.add_radiobutton(label=\"No Data\",variable=option_2)#, value=conuji)\n",
    "sub_nevbayes.add_separator()\n",
    "sub_nevbayes.add_command(label=\"Proses\", command=tren)\n",
    "nevbayes.add_cascade(label = 'Proses', menu=sub_nevbayes)\n",
    "\"\"\"\n",
    "nevbayes.add_cascade(label = 'Proses', command=tren)\n",
    "nevbayes.add_command(label = 'Show Data Latih',command = showdatlatih)\n",
    "nevbayes.add_command(label = 'Show Data Uji' ,command = showdatuji)\n",
    "nevbayes.add_separator()\n",
    "nevbayes.add_command(label ='Hasil Bag Of Words', command = bow)\n",
    "nevbayes.add_command(label ='Hasil Frekuensi', command = frekuensi)\n",
    "nevbayes.add_command(label ='Hasil Probabilitas', command = kosakata)  \n",
    "nevbayes.add_command(label ='Hasil Data Aktual Prediksi', command = dataktpred)\n",
    "nevbayes.add_command(label ='Hasil Rincian', command = rincian) \n",
    "nevbayes.add_separator()\n",
    "nevbayes.add_command(label = 'Bantuan', command=bantuconfmat)\n",
    "nevbayes.entryconfig(4, state=DISABLED)\n",
    "nevbayes.entryconfig(5, state=DISABLED)\n",
    "nevbayes.entryconfig(6, state=DISABLED)\n",
    "nevbayes.entryconfig(7, state=DISABLED)\n",
    "nevbayes.entryconfig(8, state=DISABLED)\n",
    "nevbayes.entryconfig(10, state=DISABLED)\n",
    "\n",
    "\n",
    "manualnb = Menu(root, tearoff = 0)\n",
    "menubar.add_cascade(label ='Klasifikasi Manual', menu = manualnb, state=tk.DISABLED) #state=tk.DISABLED)\n",
    "manualnb.add_command(label = 'Input Teks', command = inputteks)\n",
    "manualnb.add_command(label = 'Bantuan', command = bantu)\n",
    "#edit.add_command(label ='Paste', command = None)\n",
    "#edit.add_command(label ='Select All', command = None)\n",
    "#edit.add_separator()\n",
    "#edit.add_command(label ='Find...', command = None)\n",
    "#edit.add_command(label ='Find again', command = None)\n",
    "#newWindow.config(menu = menubar)\n",
    "\n",
    "#configure window\n",
    "root.wm_title(\"Naive Bayes Python\")\n",
    "root.geometry('670x370')\n",
    "root.configure(bg=\"aliceblue\")\n",
    "root.state(\"normal\")\n",
    "Showtemplabel = Entry(root);\n",
    "\n",
    "\"\"\"btn = Button(root, text = 'Open File', bd = '0', command = File_dialog,\n",
    "             bg = 'lightblue', fg = 'white')#, width=6, height=2)\n",
    "btn2 = Button(root, text = 'Klasifikasi', bd = '0', \n",
    "             bg = 'lightblue', fg = 'white')#, width=6, height=2)\"\"\"\n",
    "\n",
    "#define font\n",
    "myFont = font.Font(family='Helvetica', size=15, weight='bold')\n",
    "#yntktsfont = font.Font(family='Consolas', size=15, weight='bold')\n",
    "fontinputan = font.Font(family='Helvetica', size=16, weight='bold')\n",
    "\"\"\"\n",
    
    "\"\"\"\n",
    "#configure label\n",
    "inputan = Label(root, text=\"APLIKASI KLASIFIKASI TEKS\\nMENGGUNAKAN NAIVE BAYES\", bd = '0',\n",
    "                bg = 'aliceblue', fg = 'lightblue', anchor = \"e\")#, command = lambda : canvasyntkts.pack()) #command = lambda : canvasyntkts.pack_forget())\n",
    "inputan.pack(side=TOP, pady = 8, padx = 2)#place(relx = 0.5, rely = 0.06, anchor = 'center')\n",
    "\n",
    "#global cnvasyntkts\n",
    "#canvasyntkts = Canvas(root, highlightthickness=0, width = 400, height = 300,  relief = 'ridge', bg=\"lightblue\", bd=0)\n",
    "#canvasyntkts.pack()\n",
    "#yntkts = Button(root, text=\"/\", \n",
    "               #bd = '0',fg = 'aliceblue', bg = 'aliceblue', ancho r = \"e\", command = lambda : canvasyntkts.pack_forget())#command = root.destroy)\n",
    "#canvasyntkts.create_window(200, 150, window=yntkts)\n",
    "\n",
    "\n",
    "#button configure\n",
    "#btn.place(x=5, y=5)\n",
    "#btn2.place(x=90, y=5)\n",
    "#btn3.place(x=221, y=5)\n",
    "\n",
    "inputan['font']=fontinputan\n",
    "#yntkts['font']=yntktsfont\n",
    "#file_frame['font']=myFont\n",
    "label_files['font']=myFont\n",
    "\n",
    "#btn['font']=myFont\n",
    "#btn2['font']=myFont\n",
    "#btn3['font']=myFont\n",
    "\n",
    "root = mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
